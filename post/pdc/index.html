<!DOCTYPE html>
<html
  dir="ltr"
  lang="en"
  data-theme=""
  
    class="html theme--light"
  
><head>
  <title>
    
      
        COMP SCI 3305 - Parallel and Distributed Computing |
      JZ Chan

  </title>

  
  <meta charset="utf-8" /><meta name="generator" content="Hugo 0.68.3" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <meta name="author" content="JZ Chan" />
  <meta
    name="description"
    content="Jian Zhe (JZ) Chan
Student from The University of Adelaide
Penultimate Computer Science Undergraduate
------------- SKILLS -------------
C&#43;&#43; | C | C# | Python 
R | MATLAB | Visual Studio
HTML | CSS | JavaScript | Vue.js | React.js 
Node.js | AJAX | MySQL
Git | Linux
"
  />
  
  
    
    
    <link
      rel="stylesheet"
      href="/scss/main.min.ba004976221e613a16542d07a2deca5d0377ff5e6a22dec5fcec01480ba967cf.css"
      integrity="sha256-ugBJdiIeYToWVC0Hot7KXQN3/15qIt7F/OwBSAupZ88="
      crossorigin="anonymous"
      type="text/css"
    />
  

  
  <link
    rel="stylesheet"
    href="/css/markupHighlight.min.793b323d7f2d9fbfd0b93f4d593fb5ad77b918716ed33eddea403fa87f770403.css"
    integrity="sha256-eTsyPX8tn7/QuT9NWT&#43;1rXe5GHFu0z7d6kA/qH93BAM="
    crossorigin="anonymous"
    type="text/css"
  />
  
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css"
    integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css"
    integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css"
    integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css"
    integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link rel="shortcut icon" href="/favicons/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png" />

  <link rel="canonical" href="https://chanjz.github.io/post/pdc/" />

  
  
  
  
  <script
    type="text/javascript"
    src="/js/anatole-header.min.5c846cefa5ed21cceee981c70901aaf21b17b4e0b05bd777af840780918abea9.js"
    integrity="sha256-XIRs76XtIczu6YHHCQGq8hsXtOCwW9d3r4QHgJGKvqk="
    crossorigin="anonymous"
  ></script>

  
    
    
    <script
      type="text/javascript"
      src="/js/anatole-theme-switcher.min.46e991c2fcb035fc0060a792f1eb0c93ecacc9e76cd7445d6531a5cf2928686d.js"
      integrity="sha256-RumRwvywNfwAYKeS8esMk&#43;ysyeds10RdZTGlzykoaG0="
      crossorigin="anonymous"
    ></script>
  

  


  
  <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://chanjz.github.io/images/main.png"/>

<meta name="twitter:title" content="COMP SCI 3305 - Parallel and Distributed Computing"/>
<meta name="twitter:description" content="PDC Week 1 1.1 Why we need ever-increasing performance   Climate modeling"/>



  
  <meta property="og:title" content="COMP SCI 3305 - Parallel and Distributed Computing" />
<meta property="og:description" content="PDC Week 1 1.1 Why we need ever-increasing performance   Climate modeling" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chanjz.github.io/post/pdc/" />
<meta property="og:image" content="https://chanjz.github.io/images/main.png"/>
<meta property="article:published_time" content="2023-03-02T13:24:27+08:00" />
<meta property="article:modified_time" content="2023-03-02T13:24:27+08:00" /><meta property="og:site_name" content="My blog" />



  
  
  
  
  <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "articleSection": "post",
        "name": "COMP SCI 3305 - Parallel and Distributed Computing",
        "headline": "COMP SCI 3305 - Parallel and Distributed Computing",
        "alternativeHeadline": "",
        "description": "
      
        PDC Week 1 1.1 Why we need ever-increasing performance   Climate modeling


      


    ",
        "inLanguage": "en",
        "isFamilyFriendly": "true",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/chanjz.github.io\/post\/pdc\/"
        },
        "author" : {
            "@type": "Person",
            "name": "JZ Chan"
        },
        "creator" : {
            "@type": "Person",
            "name": "JZ Chan"
        },
        "accountablePerson" : {
            "@type": "Person",
            "name": "JZ Chan"
        },
        "copyrightHolder" : {
            "@type": "Person",
            "name": "JZ Chan"
        },
        "copyrightYear" : "2023",
        "dateCreated": "2023-03-02T13:24:27.00Z",
        "datePublished": "2023-03-02T13:24:27.00Z",
        "dateModified": "2023-03-02T13:24:27.00Z",
        "publisher":{
            "@type":"Organization",
            "name": "JZ Chan",
            "url": "https://chanjz.github.io/",
            "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/chanjz.github.io\/favicons\/favicon-32x32.png",
                "width":"32",
                "height":"32"
            }
        },
        "image": 
      [
        
        "https://chanjz.github.io/images/main.png"


      
      ]

    ,
        "url" : "https:\/\/chanjz.github.io\/post\/pdc\/",
        "wordCount" : "1057",
        "genre" : [ ],
        "keywords" : [ ]
    }
  </script>


</head>
<body class="body">
    <div class="wrapper">
      <aside
        
          class="wrapper__sidebar"
        
      ><div
  class="sidebar
    animated fadeInDown
  "
>
  <div class="sidebar__content">
    <div class="sidebar__introduction">
      <img
        class="sidebar__introduction-profileimage"
        src="/main.jpg"
        alt="profile picture"
      />
      
        <div class="sidebar__introduction-title">
          <a href="/">My blog</a>
        </div>
      
      <div class="sidebar__introduction-description">
        <p>Jian Zhe (JZ) Chan<br />Student from The University of Adelaide<br />Penultimate Computer Science Undergraduate<br />------------- SKILLS -------------<br />C++ | C | C# | Python <br />R | MATLAB | Visual Studio<br />HTML | CSS | JavaScript | Vue.js | React.js <br />Node.js | AJAX | MySQL<br />Git | Linux<br /></p>
      </div>
    </div>
    <ul class="sidebar__list">
      
        <li class="sidebar__list-item">
          <a
            href="mailto:chanjianzhe2002@gmail.com"
            target="_blank"
            rel="noopener me"
            aria-label="e-mail"
            title="e-mail"
          >
            <i class="fas fa-envelope fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      
        <li class="sidebar__list-item">
          <a
            href="https://www.linkedin.com/in/jian-zhe-chan-999b85235/"
            target="_blank"
            rel="noopener me"
            aria-label="Linkedin"
            title="Linkedin"
          >
            <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      
        <li class="sidebar__list-item">
          <a
            href="https://github.com/Chan-JZ"
            target="_blank"
            rel="noopener me"
            aria-label="GitHub"
            title="GitHub"
          >
            <i class="fab fa-github fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      
        <li class="sidebar__list-item">
          <a
            href="https://api.whatsapp.com/send?phone=61452633511"
            target="_blank"
            rel="noopener me"
            aria-label="WhatsApp"
            title="WhatsApp"
          >
            <i class="fab fa-whatsapp fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      
    </ul>
  </div><footer class="footer footer__sidebar">
  <ul class="footer__list">
    <li class="footer__item">
      &copy;
      
        JZ Chan
        2023
      
    </li>
    
  </ul>
</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.7d3bf3472b73d9ba107b3de37d0df8fa736593a3c6638c95eaed42006bfc0193.js"
    integrity="sha256-fTvzRytz2boQez3jfQ34&#43;nNlk6PGY4yV6u1CAGv8AZM="
    crossorigin="anonymous"
  ></script></div>
</aside>
      <main
        
          class="wrapper__main"
        
      >
        <header class="header"><div
  class="
    animated fadeInDown
  "
>
  <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
    <span aria-hidden="true" class="navbar-burger__line"></span>
    <span aria-hidden="true" class="navbar-burger__line"></span>
    <span aria-hidden="true" class="navbar-burger__line"></span>
  </a>
  <nav class="nav">
    <ul class="nav__list" id="navMenu">
      
      
        
        
          <li class="nav__list-item">
            <a
              
              href="/"
              
              title=""
              >Home</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            <a
              
              href="/post/"
              
              title=""
              >Posts</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            <a
              
              href="/portfolio/"
              
              title=""
              >Portfolio</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            <a
              
              href="/about/"
              
              title=""
              >About</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            <a
              
              href="/awards/"
              
              title=""
              >Awards</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            <a
              
              href="/certifications/"
              
              title=""
              >Certifications</a
            >
          </li>
        

      
    </ul>
    <ul class="nav__list nav__list--end">
      
      
        <li class="nav__list-item">
          <div class="themeswitch">
            <a title="Switch Theme">
              <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a>
          </div>
        </li>
      
    </ul>
  </nav>
</div>
</header>
  <div
    class="post 
      animated fadeInDown
    "
  >
    
    <div class="post__content">
      <h1>COMP SCI 3305 - Parallel and Distributed Computing</h1>
      
        <ul class="post__meta">
          <li class="post__meta-item">
            <em class="fas fa-calendar-day post__meta-icon"></em>
            <span class="post__meta-text"
              >
                
                  2/3/2023
                

              
            </span>
          </li>
          <li class="post__meta-item">
            <em class="fas fa-stopwatch post__meta-icon"></em>
            <span class="post__meta-text">5-minute read</span>
          </li>
        </ul>
      <h1 id="pdc">PDC</h1>
<h2 id="week-1">Week 1</h2>
<h3 id="11-why-we-need-ever-increasing-performance">1.1 Why we need ever-increasing performance</h3>
<ul>
<li>
<p><strong>Climate modeling</strong></p>
<ul>
<li>Need better computer models to better understand climate change</li>
<li>Models that could simulate interaction between atmosphere, ocean, solid land, ice cap.</li>
<li>How various intervention might affect global climate</li>
</ul>
</li>
<li>
<p><strong>Protein Folding</strong></p>
<ul>
<li>Misfolded proteins involved in diseases</li>
<li>Current computational power can’t study complex molecules such as proteins</li>
</ul>
</li>
<li>
<p><strong>Drug Discovery</strong></p>
<ul>
<li>Research into new medical treatments</li>
</ul>
</li>
<li>
<p><strong>Energy Research</strong></p>
<ul>
<li>Program more detailed wind turbines, solar cells</li>
</ul>
</li>
<li>
<p><strong>Data Analysis</strong></p>
<ul>
<li>Analyze a tremendous amount of data</li>
</ul>
</li>
</ul>
<hr>
<h3 id="12-why-were-building-parallel-systems">1.2 Why we’re building parallel systems</h3>
<p>Increased single processor performance by increasing density of transistors</p>
<h3 id="problem"><strong>Problem</strong></h3>
<ul>
<li>Smaller transistor = Faster processor</li>
<li>Faster processor = Increased power consumption</li>
<li>Increased power consumption = Increased heat</li>
<li>Increased heat = Unreliable processor</li>
</ul>
<p>Can’t increase the speed of processor but still can increase density of transistors. To exploit this, use parallelism</p>
<blockquote>
<p><em>parallelism</em>: put multiple, relatively simple processors on a single chip</p>
</blockquote>
<p>Such circuits are called multicore processors**.**</p>
<blockquote>
<p><strong><strong><strong>core: synonymous with CPU</strong></strong></strong></p>
</blockquote>
<blockquote>
<p><em><strong><strong><strong><strong><strong><strong><strong><strong><strong>single-core system:</strong></strong></strong></strong></strong></strong></strong></strong></strong></em> processor with one CPU</p>
</blockquote>
<hr>
<h3 id="13-why-we-need-parallel-programs">1.3 Why we need parallel programs</h3>
<ul>
<li>
<p>Running multiple instances of a serial program isn’t useful (Instead of running multiple instances of a game, we want it to run faster)</p>
<blockquote>
<p><strong><strong><strong><strong><strong><strong><strong><strong>serial program:</strong></strong></strong></strong></strong></strong></strong></strong> program written to run on a single processor, performance of such program on system with multiple processors = performance on a single processor of the multiprocessor system</p>
</blockquote>
</li>
</ul>
<h3 id="approaches-to-the-serial-problem">Approaches to the serial problem</h3>
<ul>
<li>
<p>Rewrite serial programs so that they’re parallel</p>
<blockquote>
<p><strong><strong><strong><strong><strong>parallel: can make use of multiple cores</strong></strong></strong></strong></strong></p>
</blockquote>
</li>
<li>
<p>Use translation programs</p>
<blockquote>
<p><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>translation program: program that will automatically convert serial programs into parallel programs</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></p>
</blockquote>
<ul>
<li>Very difficult, limited success, requires complex program analysis</li>
<li>Output likely inefficient</li>
<li>Sometimes best to devise a new algorithm</li>
</ul>
</li>
</ul>
<h3 id="example-devising-new-algorithm">Example (devising new algorithm)</h3>
<p>Computer n values and add them together</p>
<ul>
<li>Serial solution</li>
</ul>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled.png" alt="Untitled"></p>
<ul>
<li>Parallel solution
<ul>
<li>Suppose we have p cores, p much smaller than n.</li>
<li>Each core form partial sum of n/p values</li>
</ul>
</li>
</ul>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled%201.png" alt="Untitled"></p>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled%202.png" alt="Untitled"></p>
<h3 id="reduction-pattern---better-parallel-algorithm-to-add-up-the-partial-sums">Reduction Pattern - Better parallel algorithm to add up the partial sums</h3>
<ul>
<li>Don’t let master core do all the work, share among other cores
<ol>
<li>Odd and even pairs (add 1 to 0, 3 to 2, …)</li>
<li>Cores divisible by 2 (add 2 to 0, 6 to 4, …)</li>
<li>Cores divisible by 4 (add 4 to 0, 12 to 8, …)</li>
<li>So on and so forth</li>
</ol>
</li>
</ul>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled%203.png" alt="Untitled"></p>
<p>With 8 cores (master core)</p>
<ul>
<li>First method: 7 receives and adds</li>
<li>Second method: 3 receives and adds</li>
</ul>
<p>With 1000 cores (master core)</p>
<ul>
<li>First method: 999 receives and adds</li>
<li>Second method: 10 receives and adds</li>
</ul>
<h3 id="sending-mechanism">Sending mechanism</h3>
<ul>
<li>How to send a number from one core to another</li>
<li>Calculate distance between cores</li>
</ul>
<h3 id="takeaway">Takeaway</h3>
<ul>
<li>
<p>Highly unlikely that a translation program would discover the second method</p>
</li>
<li>
<p>Cannot simply write large serial constructs and parallelize them</p>
<blockquote>
<p><em>parallelize</em>: Modifying a program so that it can use multiple cores</p>
</blockquote>
</li>
<li>
<p>Must write parallel programs</p>
<blockquote>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong>parallel program:</strong></strong></strong></strong></strong></strong></strong></strong></strong> program that exploits the power of multiple processors</p>
</blockquote>
</li>
</ul>
<hr>
<h3 id="14-how-to-write-parallel-programs">1.4 How to write parallel programs</h3>
<ul>
<li>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Task-parallelism</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<ul>
<li>partition various tasks carried out solving the problem among the cores</li>
</ul>
</li>
<li>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Data-parallelism</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<ul>
<li>partition the data used in solving the problem among the cores</li>
<li>each core carries out similar operations on its part of the data</li>
</ul>
</li>
</ul>
<h3 id="example">Example</h3>
<p>Prof P, Teaching assistants A, B, C, D</p>
<p>100 students, 5 questions each</p>
<p>Task-parallelism</p>
<ul>
<li>Each of them grade all 100 papers to 1 of the question</li>
<li>P grades Q1, A grades Q2, B grades Q3, …</li>
<li>Each person grades a different question (different task)</li>
</ul>
<p>Data-parallelism</p>
<ul>
<li>Divide 100 papers into 5 piles of 20 papers each</li>
<li>Each of them grade all papers in 1 of the piles</li>
<li>Each person grades all 5 questions (same/similar task)</li>
</ul>
<h3 id="comparison">Comparison</h3>
<p>Task-parallelism</p>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>Master core: receiving and adding the cores’ partial sums</li>
<li>Other cores: giving the partial sum to the master core</li>
</ul>
<p>Data-parallelism</p>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>data: value computed by <strong><strong><strong><strong><strong>Compute_next_value</strong></strong></strong></strong></strong></li>
<li>each core carries roughly the same operation: computes the require values by calling <em><strong><strong><strong><strong><strong><strong><strong><strong><strong>Compute_next_value and adds them together</strong></strong></strong></strong></strong></strong></strong></strong></strong></em></li>
</ul>
<h3 id="coordination">Coordination</h3>
<p>Cores usually need to coordinate their work</p>
<ul>
<li>
<p><strong>Communication</strong></p>
<ul>
<li>1 or more cores send info to another core</li>
</ul>
</li>
<li>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Load balancing</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<ul>
<li>All cores assigned roughly the same number of values to compute</li>
</ul>
</li>
<li>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Synchronization</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<ul>
<li>Each core works at its own pace</li>
<li>Make sure a core doesn’t get too far ahead</li>
<li>Example
<ul>
<li>
<p>master core read values from <strong><strong><strong>stdin</strong></strong></strong> and store in an array <strong>x</strong></p>
</li>
<li>
<p>Don’t want other cores to start computing partial sums before master is done initializing x</p>
</li>
<li>
<p>synchronization between initialization of x and computation of partial sums</p>
<blockquote>
<p>Use function <strong><strong><strong><strong><strong><strong>Synchronize_cores.</strong></strong></strong></strong></strong></strong> Each core will wait in the function until all cores have entered the function - in particular the master core</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Currently, most powerful programs written using explicit parallel constructs</p>
<blockquote>
<p><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>explicit parallel construct:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em> programs that include explicit instructions for parallelism: core 0 executes task 0, core 1 executes task 1, …, all cores synchronize, …</p>
</blockquote>
<p>Other options for writing parallel program - higher level languages - tend to sacrifice performance in order to make program development easier.</p>
<hr>
<h3 id="15-what-well-be-doing">1.5 What we’ll be doing</h3>
<p>Write programs that are explicitly parallel, using C language and 3 different extensions:</p>
<ul>
<li>Message-Passing Interface (MPI)</li>
<li>POSIX threads (Pthreads)</li>
<li>OpenMP</li>
</ul>
<h3 id="2-main-parallel-systems">2 main parallel systems</h3>
<ul>
<li>
<p>************<strong>Shared-memory system (Pthread, OpenMP)</strong></p>
<ul>
<li>Cores can share access to the computer’s memory</li>
<li>In theory, each core can read and write each memory location</li>
<li>Coordinate the cores by having them examine and update shared-memory locations</li>
</ul>
</li>
<li>
<p>**************************************************<strong>Distributed-memory system (MPI)</strong></p>
<ul>
<li>Each core has its own private memory</li>
<li>Cores must communicate explicitly (sending msg across a network)</li>
</ul>
</li>
</ul>
<p><img src="PDC%20515b3b82d7204d8680bcea04391d0739/Untitled%206.png" alt="Untitled"></p>
<hr>
<h3 id="16-concurrent-parallel-distributed">1.6 Concurrent, parallel, distributed</h3>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Concurrent Computing</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<ul>
<li>A program is one in which multiple tasks can be ***********<em>in progress</em> at any instant</li>
</ul>
<p><strong>Parallel Computing</strong></p>
<ul>
<li>A program is one in which multiple tasks <strong><strong><strong><strong><strong><strong><strong><strong><strong>cooperate closely</strong></strong></strong></strong></strong></strong></strong></strong></strong>  to solve a problem</li>
<li>Runs multiple tasks simultaneously on cores that are physically close to each other and that either share the same memory or are connected by a very high-speed network</li>
<li>Eg: The 2 concurrent addition programs</li>
</ul>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Distributed Computing</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<ul>
<li>A program may need to cooperate with <em><strong><strong><strong><strong><strong><strong><strong>other programs</strong></strong></strong></strong></strong></strong></strong></em> to solve a problem</li>
<li>Tend to be more “loosely coupled”. Tasks may be executed by multiple computers separated by large distances, tasks executed by programs created independently.</li>
<li>Eg: Web search program</li>
</ul>
<hr>
<h3 id="concluding-remarks">Concluding Remarks</h3>
<ul>
<li>The laws of physics have brought us to the doorstep of multicore technology</li>
<li>Serial programs typically don’t benefit from multiple cores
<ul>
<li>Automatic parallel program generation from serial program code isn’t the most efficient approach to get high performance from multicore computers</li>
</ul>
</li>
<li>Learning to write parallel programs involves learning how to coordinate the cores</li>
<li>Parallel programs are usually very complex and therefore, require sound program techniques and development</li>
</ul>
</div>
    <div class="post__footer">
      

      
    </div>

    
  </div>

      </main>
    </div><footer class="footer footer__base">
  <ul class="footer__list">
    <li class="footer__item">
      &copy;
      
        JZ Chan
        2023
      
    </li>
    
  </ul>
</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.7d3bf3472b73d9ba107b3de37d0df8fa736593a3c6638c95eaed42006bfc0193.js"
    integrity="sha256-fTvzRytz2boQez3jfQ34&#43;nNlk6PGY4yV6u1CAGv8AZM="
    crossorigin="anonymous"
  ></script></body>
</html>
